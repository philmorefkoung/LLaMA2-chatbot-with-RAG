{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e8056e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "import numpy as np\n",
    "import json\n",
    "from langchain.vectorstores import Pinecone\n",
    "import os\n",
    "from getpass import getpass\n",
    "from langchain.llms import Replicate\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import ConversationChain as chain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import re\n",
    "import string\n",
    "from langchain.chains import LLMChain, ConversationChain\n",
    "from langchain.chains.conversation.memory import (ConversationBufferMemory, \n",
    "                                                  ConversationSummaryMemory, \n",
    "                                                  ConversationBufferWindowMemory,\n",
    "                                                  ConversationKGMemory)\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "from langchain.chains import ReduceDocumentsChain, MapReduceDocumentsChain, StuffDocumentsChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "900c4fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "# your api key \n",
    "\n",
    "REPLICATE_API_TOKEN = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ce27bdd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r8_8rCGHxwxv6TI0mQE8LhkeyJG49W2OdW2ojTUi\n"
     ]
    }
   ],
   "source": [
    "print(REPLICATE_API_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c9597705",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"REPLICATE_API_TOKEN\"] = REPLICATE_API_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d050a2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_new_tokens changes the max tokens allowed to be output by llama\n",
    "# put your llama2 model in model \n",
    "llm = Replicate(\n",
    "    model=\"\",\n",
    "    model_kwargs={\"max_new_tokens\": 8888, \"temperature\": 0.01} \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48321b57",
   "metadata": {},
   "source": [
    "# Query from Pinecone and Resume Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5b21998",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pinecone' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m index_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlangchain-retrieval-augmentation\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m pinecone\u001b[38;5;241m.\u001b[39minit( api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      3\u001b[0m               environment\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mus-west1-gcp-free\u001b[39m\u001b[38;5;124m'\u001b[39m ) \n\u001b[1;32m      4\u001b[0m index \u001b[38;5;241m=\u001b[39m pinecone\u001b[38;5;241m.\u001b[39mIndex(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pinecone' is not defined"
     ]
    }
   ],
   "source": [
    "# enter your api key and index name from your pinecone database\n",
    "index_name = 'langchain-retrieval-augmentation'\n",
    "pinecone.init( api_key='', \n",
    "              environment='us-west1-gcp-free' ) \n",
    "index = pinecone.Index('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb482a03",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SentenceTransformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# enter a job description\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m SentenceTransformer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBAAI/bge-small-en\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m job_desc \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      4\u001b[0m embedded_job \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(job_desc, normalize_embeddings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SentenceTransformer' is not defined"
     ]
    }
   ],
   "source": [
    "# enter a job description\n",
    "model = SentenceTransformer('BAAI/bge-small-en')\n",
    "job_desc = [\"\"]\n",
    "embedded_job = model.encode(job_desc, normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b77c0b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_query = np.array(embedded_job).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c362284b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# queries pinecone database based on your embedded job description\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m out \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39mquery(\n\u001b[1;32m      3\u001b[0m     vector \u001b[38;5;241m=\u001b[39m q3,\n\u001b[1;32m      4\u001b[0m     namespace\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m     include_metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m      6\u001b[0m     top_k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m      7\u001b[0m out\n",
      "\u001b[0;31mNameError\u001b[0m: name 'index' is not defined"
     ]
    }
   ],
   "source": [
    "# queries pinecone database based on your embedded job description\n",
    "out = index.query(\n",
    "    vector = q3,\n",
    "    namespace='',\n",
    "    include_metadata=True, \n",
    "    top_k = 4)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2436709",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m extracted_contents \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw_text\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(.*?)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(out), re\u001b[38;5;241m.\u001b[39mDOTALL)\n\u001b[1;32m      2\u001b[0m extracted_contents \u001b[38;5;241m=\u001b[39m [content\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m content \u001b[38;5;129;01min\u001b[39;00m extracted_contents]\n\u001b[1;32m      3\u001b[0m extracted_contents[\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "extracted_contents = re.findall(r\"'raw_text'(.*?)'score'\", str(out), re.DOTALL)\n",
    "extracted_contents = [content.strip() for content in extracted_contents]\n",
    "extracted_contents[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2b0aa0",
   "metadata": {},
   "source": [
    "# get names from each resume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d8c1fb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = re.findall(r\"'name'(.*?)'raw_text'\", str(out), re.DOTALL)\n",
    "names = [content.strip() for content in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fdd0bcf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m name_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m names:\n\u001b[1;32m      3\u001b[0m     name \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(i))\n\u001b[1;32m      4\u001b[0m     name \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[^A-Za-z0-9 ]+\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, name)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'names' is not defined"
     ]
    }
   ],
   "source": [
    "name_list = []\n",
    "for i in names:\n",
    "    name = re.sub(r'\\\\n',\" \", str(i))\n",
    "    name = re.sub(r'[^A-Za-z0-9 ]+', ' ', name)\n",
    "    name = \" \".join(name.split())\n",
    "    name_list.append(name)\n",
    "\n",
    "print(name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ec9d0eae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_resumes = len(name_list)\n",
    "num_resumes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cf1022",
   "metadata": {},
   "source": [
    "# get resumes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "36f08f21",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "resume_list = []\n",
    "# all replace/re.sub for symbols should occur before re.sub(r'[^A-Za-z0-9 ]+', ' ', s)\n",
    "for i in extracted_contents:\n",
    "    s = str(i).replace(\"\\'\", \" \")\n",
    "    s = s.replace(\"\\\\\\\\t\", \" \")\n",
    "    s = s.replace(\"\\\\t\", \" \")\n",
    "    s = re.sub(r'\\n',\" \", s)\n",
    "    s = re.sub(r'/n', ' ', s)\n",
    "    s = re.sub(r'\\\\n', ' ', s)\n",
    "    s = re.sub(r'[^A-Za-z0-9 ]+', ' ', s)\n",
    "    s = s.replace(\"raw_text :\", \" \")\n",
    "    s = s[2:]\n",
    "    s = \" \".join(s.split())\n",
    "    s = re.sub(r'uf0b7', '', s)\n",
    "    resume_list.append(\" New Resume: \" + s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce30c1a",
   "metadata": {},
   "source": [
    "# Map Reduce and Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "baa29e07",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=s\n",
    "    )\n",
    "    for s in resume_list\n",
    "    \n",
    "]\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d66e116f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_split = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    # the smaller chunk size the longer it takes to run\n",
    "    chunk_size = 300, chunk_overlap = 2)\n",
    "docs = text_split.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce5dfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map\n",
    "map_template = \"\"\"[INST] <<SYS>> You are a helpful assistant.'<</SYS>> \n",
    "The following contains\"\"\" + str(num_resumes) + \"\"\" resumes from \"\"\" + str(name_list) + \"\"\". \n",
    "Each candidate's resume is delimited with the phrase 'New Resume:' followed by the candidate's name, {docs}. \n",
    "Use ONLY the resumes provided and based on this list of resumes, please identify the key skills, experience, and education of each resume\n",
    "Helpful Answer: [/INST]\"\"\"\n",
    "map_prompt = PromptTemplate.from_template(map_template)\n",
    "map_chain = LLMChain(llm=llm, prompt=map_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "db145e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce\n",
    "reduce_template = \"\"\"[INST] <<SYS>> You are a helpful assistant<</SYS>> The following contains the key skills of each person's resume:\n",
    "{doc_summaries}\n",
    "Take these and put it into a ranking of most skilled, most experience, and best education, please include the names of each resume \n",
    "and why you ranked them where they are. Helpful Answer: [/INST]\"\"\"\n",
    "reduce_prompt = PromptTemplate.from_template(reduce_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fb3f4ed1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run chain\n",
    "reduce_chain = LLMChain(llm=llm, prompt=reduce_prompt)\n",
    "\n",
    "# Takes a list of documents, combines them into a single string, and passes this to an LLMChain\n",
    "combine_documents_chain = StuffDocumentsChain(\n",
    "    llm_chain=reduce_chain, document_variable_name= \"doc_summaries\"\n",
    ")\n",
    "\n",
    "# Combines and iteravely reduces the mapped documents\n",
    "reduce_documents_chain = ReduceDocumentsChain(\n",
    "    # This is final chain that is called.\n",
    "    combine_documents_chain=combine_documents_chain,\n",
    "    # If documents exceed context for `StuffDocumentsChain`\n",
    "    collapse_documents_chain=combine_documents_chain,\n",
    "    # The maximum number of tokens to group documents into. (not 1 to 1 with llama2's 4096 limit)\n",
    "    token_max=3300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "66ea8d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining documents by mapping a chain over them, then combining results\n",
    "map_reduce_chain = MapReduceDocumentsChain(\n",
    "    # Map chain\n",
    "    llm_chain=map_chain,\n",
    "    # Reduce chain\n",
    "    reduce_documents_chain=reduce_documents_chain,\n",
    "    # The variable name in the llm_chain to put the documents in\n",
    "    document_variable_name=\"docs\",\n",
    "    # Return the results of the map steps in the output\n",
    "    return_intermediate_steps=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9f08fbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapreduce_output = map_reduce_chain.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9829d9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mapreduce_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 3 resumes\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(mapreduce_output)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mapreduce_output' is not defined"
     ]
    }
   ],
   "source": [
    "# 3 resumes\n",
    "print(mapreduce_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ced32b",
   "metadata": {},
   "source": [
    "# Everything Put Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "37d7a044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getresumes(job_desc, num):\n",
    "    model = SentenceTransformer('BAAI/bge-small-en')\n",
    "    embedded_job_desc = model.encode(str(job_desc), normalize_embeddings=True)\n",
    "\n",
    "    resumes = index.query(\n",
    "                vector = np.array(embedded_job_desc).tolist(),\n",
    "                namespace='',\n",
    "                include_metadata=True,\n",
    "                top_k = int(num))\n",
    "    \n",
    "    extracted_contents = re.findall(r\"'raw_text'(.*?)'score'\", str(resumes), re.DOTALL)\n",
    "    extracted_contents = [content.strip() for content in extracted_contents]\n",
    "    \n",
    "    resume_list = []\n",
    "    \n",
    "    # all replace/re.sub for symbols that include letters such as \\\\\\\\t should occur before re.sub(r'[^A-Za-z0-9 ]+', ' ', s)\n",
    "    for i in extracted_contents:\n",
    "        s = str(i).replace(\"\\'\", \" \")\n",
    "        s = s.replace(\"\\\\\\\\t\", \" \")\n",
    "        s = s.replace(\"\\\\t\", \" \")\n",
    "        s = re.sub(r'\\n',\" \", s)\n",
    "        s = re.sub(r'/n', ' ', s)\n",
    "        s = re.sub(r'\\\\n', ' ', s)\n",
    "        s = re.sub(r'[^A-Za-z0-9 ]+', ' ', s)\n",
    "        s = s.replace(\"raw_text :\", \" \")\n",
    "        s = s[2:]\n",
    "        s = \" \".join(s.split())\n",
    "        s = re.sub(r'uf0b7', '', s)\n",
    "        resume_list.append(\" New Resume: \" + s)\n",
    "    \n",
    "    # make resume_list into Document type\n",
    "    docs = [Document(page_content=s) for s in resume_list]\n",
    "    \n",
    "    name_list = []\n",
    "    \n",
    "    names = re.findall(r\"'name'(.*?)'raw_text'\", str(resumes), re.DOTALL)\n",
    "    names = [content.strip() for content in names]\n",
    "    for i in names:\n",
    "        name = re.sub(r'\\\\n',\" \", str(i))\n",
    "        name = re.sub(r'[^A-Za-z0-9 ]+', ' ', name)\n",
    "        name = \" \".join(name.split())\n",
    "        name_list.append(name)\n",
    "    return(docs, name_list)        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d4e37cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapreduce(docs, name_list, map_prompt, reduceprompt):\n",
    "    \n",
    "    text_split = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    # the smaller chunk size the longer it takes to run\n",
    "    chunk_size = 100, chunk_overlap = 0)\n",
    "    docs = text_split.split_documents(docs)\n",
    "    # Map\n",
    "    map_template = \"\"\"[INST] <<SYS>> Your job is to extract key components from each resume provided <</SYS>>\n",
    "    The following contains\"\"\" + str(len(name_list)) + \"\"\" resumes from \"\"\" + str(name_list) + \"\"\". \n",
    "    Each candidate's resume is delimited with the phrase 'New Resume:' followed by the candidate's name, {docs}. \n",
    "    Using ONLY the resumes provided and based on this list of resumes,\"\"\" + map_prompt + \"\"\"    \n",
    "    Helpful Answer: [/INST]\"\"\"\n",
    "    \n",
    "    map_prompt = PromptTemplate.from_template(map_template)\n",
    "    map_chain = LLMChain(llm=llm, prompt=map_prompt)\n",
    "    \n",
    "    # Reduce\n",
    "    reduce_template = \"\"\"[INST] <<SYS>> Your job is to rank candidates using only the information provided for a certain job<</SYS>> The following contains the key skills of each person's resume:\n",
    "    {doc_summaries}. Please \"\"\" + reduceprompt + \"\"\"\n",
    "    Helpful Answer: [/INST]\"\"\"\n",
    "    reduce_prompt = PromptTemplate.from_template(reduce_template)\n",
    "    \n",
    "    # Run chain\n",
    "    reduce_chain = LLMChain(llm=llm, prompt=reduce_prompt)\n",
    "\n",
    "    # Takes a list of documents, combines them into a single string, and passes this to an LLMChain\n",
    "    combine_documents_chain = StuffDocumentsChain(\n",
    "        llm_chain=reduce_chain, document_variable_name= \"doc_summaries\"\n",
    "    )\n",
    "\n",
    "    # Combines and iteravely reduces the mapped documents\n",
    "    reduce_documents_chain = ReduceDocumentsChain(\n",
    "        # This is final chain that is called.\n",
    "        combine_documents_chain=combine_documents_chain,\n",
    "        # If documents exceed context for `StuffDocumentsChain`\n",
    "        collapse_documents_chain=combine_documents_chain,\n",
    "        # The maximum number of tokens to group documents into. (not 1 to 1 with llama2's 4096 limit)\n",
    "        token_max=3300,\n",
    "    )\n",
    "    \n",
    "    # Combining documents by mapping a chain over them, then combining results\n",
    "    map_reduce_chain = MapReduceDocumentsChain(\n",
    "        # Map chain\n",
    "        llm_chain=map_chain,\n",
    "        # Reduce chain\n",
    "        reduce_documents_chain=reduce_documents_chain,\n",
    "        # The variable name in the llm_chain to put the documents in\n",
    "        document_variable_name=\"docs\",\n",
    "        # Return the results of the map steps in the output\n",
    "        return_intermediate_steps=False,\n",
    "    )\n",
    "    \n",
    "    output = map_reduce_chain.run(docs)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f97aa7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot_template = \"\"\"[INST] <<SYS>>You are an assistant to a recruiter that finds the best candidates for jobs. \n",
    "        You are to ONLY use the information provided to you to formulate your responses.\n",
    "        You are designed to provide information on candidates based on the information given and if asked, evaluate candidates and give them an overall (based on multiple criteria such as education, relevant experience, and other skills) ranking from best match to worst match. \n",
    "        While doing so you should be able to justify why a candidate is ranked where they are.<</SYS>> [/INST]\n",
    "\n",
    "        {history}\n",
    "        Human: {human_input}\n",
    "        Assistant:\"\"\"\n",
    "\n",
    "chatbot_prompt = PromptTemplate(input_variables=[\"history\", \"human_input\"], template=chatbot_template)\n",
    "llm_chain = LLMChain(llm = llm,\n",
    "                    prompt = chatbot_prompt,\n",
    "                    verbose=False,\n",
    "                    memory=ConversationBufferWindowMemory(k=3),\n",
    "                    llm_kwargs={\"max_length\": 4096})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17694c40",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(docs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'docs' is not defined"
     ]
    }
   ],
   "source": [
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4982c30f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 2\u001b[0m     jobdesc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease enter a job description: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m     num \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease enter the number of resumes you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md like: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     docs, names \u001b[38;5;241m=\u001b[39m getresumes(jobdesc, \u001b[38;5;28mint\u001b[39m(num))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py:1175\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[1;32m   1173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1174\u001b[0m     )\n\u001b[0;32m-> 1175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[1;32m   1176\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[1;32m   1177\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1178\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1179\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1180\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py:1217\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1216\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    jobdesc = input(\"Please enter a job description: \\n\")\n",
    "    num = input(\"Please enter the number of resumes you'd like: \\n \")\n",
    "    \n",
    "    docs, names = getresumes(jobdesc, int(num))\n",
    "\n",
    "    mapp = input(\"How would you like to map these resumes? \\n\")\n",
    "    reduce = input(\"How would you like to reduce (rank) these resumes? \\n\")\n",
    "    \n",
    "    mapped_docs = mapreduce(docs, names, mapp, reduce)\n",
    "    print(mapped_docs)\n",
    "    \n",
    "    while True:\n",
    "        inn = input(\"What would you like to know from these resumes? \\n\")\n",
    "        print(llm_chain.predict(human_input=\"[INST] <<SYS>> use only the information provided here:\" + str(mapped_docs) + \" to formulate your response <</SYS>>\" + inn + \"[/INST]\"))\n",
    "            \n",
    "        if inn.lower() == 'exit':\n",
    "            break\n",
    "            \n",
    "    in5 = input(\"type exit to exit \\n\")\n",
    "\n",
    "    if in5.lower() == 'exit':\n",
    "            break\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92584aed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
